# Hansard-LLM-Report-Summarizer

## Project Overview
This project automates the process of downloading Hansard reports from the Canadian House of Commons, extracting relevant text, and generating summaries using various language models. It is designed to help users quickly understand key discussions and debates on specific topics from parliamentary sessions.

## Use Cases
- Automatically download Hansard reports from sitting days.
- Extract relevant sections of text based on a topic of interest.
- Generate summaries using multiple pre-trained language models.
- Compare summaries across different models for more accurate insights.

## Folder Structure
```bash
hansard_report_summarizer/
├── README.md                    # Project overview and usage instructions
├── requirements.txt             # Dependencies to run the project
├── main.py                      # Main entry point to run the entire summarization pipeline
├── .gitignore                   # Specifies files and folders to ignore in Git
├── data/                        # Directory for input/output files (raw or processed data)
├── output/                      # Directory for generated outputs (summaries, logs, etc.)
├── notebooks/                   # Jupyter notebooks for demonstration and experimentation
│   └── hansard_demo.ipynb       # Demo notebook for the summarization pipeline
│
└── src/                          # Core scripts for the project
    ├── data_downloader.py        # Script for downloading Hansard reports
    ├── text_extractor.py         # Script for extracting text from downloaded PDFs
    ├── summarizer.py             # Script for generating summaries using language models
    └── model_comparison.py       # Script for comparing summaries from different models
```

## Setup Instructions

### Prerequisites
Ensure you have Python 3.8 or higher installed.

### Installation
#### 1. Clone this repository:
```bash
git clone https://github.com/yourusername/hansard_report_summarizer.git
cd hansard_report_summarizer
```
#### 2. Install the required Python packages:
```bash
pip install -r requirements.txt
```

## Model Management
This project uses Ollama to manage and run large language models (LLMs) for summarization purposes. Please follow the instructions below to ensure that the required models are available before running the summarization process.

### Required Models
The following models are used in this project:
- Mistral 7B
- Gemma 2 9B
- LLaMA 3.1 8B

### Loading Models with Ollama
Before running the summarization, make sure you have the necessary models loaded into Ollama. You can do this by executing the following commands:
```bash
# Pull the models using Ollama
ollama pull mistral-7b
ollama pull gemma-2-9b
ollama pull llama-3-1-8b
```
To verify that the models are available, you can list all models with:
```bash
ollama list
```
Ensure that the output includes the models mentioned above. If a model is not available, please pull it using the command provided.

### Troubleshooting Model Loading
If you encounter issues while loading a model, check the following:
- **Network Connectivity**: Make sure you are connected to the internet to pull models from Ollama.
- **Model Version**: Ensure you are using the correct version of the model as required by the script. Version mismatches can cause unexpected issues.

## Usage

### Download and Summarize Hansard Reports
Run the main script to download Hansard reports and generate summaries based on a topic of interest:
```bash
python main.py --start_date YYYY-MM-DD --end_date YYYY-MM-DD --topic "Climate change" --summary_length "medium"
```

- **`--start_date`**: Start date of the Hansard report in `YYYY-MM-DD` format (required).
- **`--end_date`**: End date of the Hansard report in `YYYY-MM-DD` format (optional, defaults to start date).
- **`--topic`**: The topic of interest for which to extract and summarize text (required).
- **`--summary_length`**: The length of the summary, options are `short`, `medium`, or `long` (optional, default is `medium`).
- **`--reference_summary`**: (Optional) Provide a reference summary for ROUGE-L evaluation.

### View Summaries and ROUGE-L Scores
Summaries generated by different models, along with ROUGE-L scores (if a reference summary is provided), will be printed in the log output. You can also find the results saved in a CSV file.

